\documentclass{mipt-thesis-ms}
% Следующие две строки нужны только для biblatex. Для inline-библиографии их следует убрать.
%\usepackage{mipt-thesis-biblatex}
%\addbibresource{example.bib}

\title{Рекомендательные системы, основанные на графовых нейронных сетях}
\author{Минеев Н.\,Р.}
\supervisor{Киселёв Д.\,А.}
\referee{Петров Д.\,Е.}       % требуется только для mipt-thesis-ms
\groupnum{M05-114a}
\faculty{Физтех-школа Прикладной Математики и Информатики}
\department{Кафедра алгоритмов и технологий программирования}


% так можно определять команду для повторяющихся обозначений,
% чтобы не набирать каждый раз заново
\newcommand{\E}{\ensuremath{\mathsf{E}}}  % матожидание
\newcommand{\D}{\ensuremath{\mathsf{D}}}  % дисперсия
\newcommand{\Prb}{\ensuremath{\mathsf{P}}}  % вероятностная мера

\newcommand{\eps}{\varepsilon}  % нормальная буква эпсилон
\renewcommand{\phi}{\varphi}  % нормальная буква фи

\renewcommand{\le}{\leqslant}  % нормальный знак <=
\renewcommand{\leq}{\leqslant}  % нормальный знак <=
\renewcommand{\ge}{\geqslant}  % нормальный знак >=
\renewcommand{\geq}{\geqslant}  % нормальный знак >=

\newtheorem{lemma}{Лемма}  % создаёт команд для лемм, можно сделать так же для любого другого вида утверждений
\newtheorem{Def}{Определение}[section]





\begin{document}

\frontmatter
\titlecontents

\mainmatter


\chapter{Введение}
Здесь идет текст. Вот так выглядит ссылка на библиографию \cite{langmuir26}. Аналогично добавляются еще главы, внутри них можно объявлять секции с помощью \verb|\section|.


\chapter{Основные понятия и определения}
В данной главе приводятся определения, описание подходов и методов

\section{Общая постановка задачи рекомендаций и методы решения}
{\bf Постановка задачи рекомендаций.} 
Задано множество пользователей $U$ и множество товаров $I$, и существует целевая функция $r: U \times I \times \mathcal{T} \rightarrow R$, выражающая результат взаимодействия пользователей с товарами, где $R$ --- линейно упорядоченное множество возможных результатов взаимодействия, $\mathcal{T}$ --- время.

{\bf Задача рекомендации $K$ товаров:} По известной до момента времени $Т \in \mathcal{T}$ истории взаимодействий пользователей с товарами $\{u, i, t, r_{ui}^t\}^{t<T}_{u \in U,\:i \in I}$, необходимо 
\begin{enumerate}
    \item для момента времени $T$ построить аппроксимацию целевой функции $\hat r^T: U \times I \rightarrow R$;
    \item для каждого пользователя отранжировать товары по убыванию аппроксимированного результата взаимодействия в момент времени $Т$, взять первые $K$ товаров в качестве рекоммендованных.
\end{enumerate}

Для простоты, здесь и далее будем предполагать $К = 1$, а $R = \{0, 1\}$, где результат взаимодейтсвия $1$ будет интерпретироваться как положительный (понравилось, лайк, покупка, итд), а $0$ как отрицательный (не понравилось, дизлайк, отказ от покупки итд). Все приведенные в работе рассуждения несложно обобщаются на случай большего $К$ и большей мощности множества $R$, тем не менее оставим данное обобщение для будущих исследований.

{\it Для решения задачи рекомендации} применяют два основных подхода: контентный и коллаборативная фильтрация.
\\

{\bf Контентный подход решения задачи рекомендации.} В контентном подходе, пользователю рекоммендуются товары, похожие на понравившиеся ему ранее.

Пусть для каждого товара $i \in I$ имеется его признаковое описание $h_i \in \mathbb{R}^n$. Тогда для решения задачи рекомендации задаются функция аггрегации последовательности признаковых описаний товаров произвольной длины $l$ $agg: (\mathbb{R}^n)^l \rightarrow \mathbb{R}$ и, в пространстве признаковых описаний товаров, метрика $d: \mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}$. \\
На первом шаге с помощью функции аггрегации строится профиль пользователя как аггрегация признаковых описаний товаров, с которыми данный пользователь провзаимодействовал $h_u = agg(\{h_i\})$. \\
На следующем шаге в качестве рекомендации пользователю выбирается товар, признаковое описание которого к профилю пользователя оказалось ближайшим: $i_{rec} = \arg \min_i d(h_u, h_i)$. [P. Lops, M. d. Gemmis, and G. Semeraro, “Content-based recommender systems: State of the art and trends,”
Recommender systems handbook, pp. 73–105, 2011.]
\\

{\it Основное преимущество} контентного подхода в поддержке холодного старта для товаров и несложной интерпретируемости, объяснимости рекомендаций. {\it Недостаток} --- остутствие новизны: рекомендации основываются на похожих товарах.

{\bf Метод коллаборативной фильтрации для решения задачи рекомендации.} В случае коллаборативной фильтрации, пользователю рекоммендуются товары, понравившиеся похожим на данного пользователя пользователям.

Пусть для каждого товара $i \in I$ и пользователя $u \in U$ имеется признаковое описание, соответственно, $h_i \in \mathbb{R}^n$ и $h_u \in \mathbb{R}^n$. Тогда для решения задачи рекомендации определяется понятие окрестности пользователя $S(u)$ в пространстве $U$, а также задаются функция скоринга $score: \mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}$, преобразующая пару признаковых описаний пользователя и товара в действительный число --- оценку, характеризующую привлекательность пользователю данного товара, и функция аггрегации последовательности оценок длины $l$ $agg: \mathbb{R}^l \rightarrow \mathbb{R}$. \\
На первом шаге с помощью функций скоринга и аггрегации оценок вычисляются приближенные рейтинги пользователя для каждого товара $\hat r_{ui} = {agg}_{v \in S(u)}(score(h_v, h_i))$. \\
На следующем шаге в качестве рекомендации пользователю выбирается товар, для которого приближенный рейтинг пользователя максимальный $i_{rec} = \arg \max_i \hat r_{ui}$. [https://arxiv.org/pdf/2206.02631.pdf]
\\

{\it Основное преимущество} коллаборативной фильтрации в более высоком качестве рекомендаций, но проблему холодного старта необходимо решать отдельно.
\\

{\bf Графовая структура задачи рекомендации.}\\
{\bf Граф} --- двойка, состоящая из множества вершин $V$ и множества пар элементов множества вершин, называемых ребрами $E \subseteq V \times V$: \:$G = <V, E>$.\\
{\bf Нейронные сети} --- метод машинного обучения, позволяющий извлекать информацию из данных, подобным человеческому мозгу образом.\\
{\bf Графовые нейронные сети (GNN)} --- тип нейронных сетей, позволяющих извлекать сложноструктурированную информацию из графов. \\
В основе графовых нейронных сетей лежит парадигма\\{\bf обмена сообщениями (message passing)}:
\\На нулевой итерации для каждой вершины графа $v \in V$ иницилизируется соответствующее векторное представление $x_v^0 \in \mathbb{R}^n$.
\\На каждой последующей итерации $t+1$:
\begin{enumerate}
    \item с помощью функции-сообщений $msg$ для каждого ребра графа $e = (u, v) \in E$ вычисляется сообщение: $m_e^{t+1} = msg(x_u^t, x_v^t, w_e^t)$
    \item для каждой вершины графа $v \in V$ вычисляется обновленное векторное представление с помощью функции аггрегации сообщений от ребер $agg$, инцидентных данной вершине, и функции обновления $upd$: $x_v^{t+1} = upd(x_v^t, agg(\{m_e^{t+1}: (u, v) \in E\}))$
\end{enumerate}

Таким образом, по окончании $k$-итерационной процедуры векторные представления вершин содержат информацию о своих соседях до $k$го порядка. Часто, итерации называют слоями, а саму графовую нейронную сеть, как следствие, $k$-слойной.
\\

В силу того, что процесс взаимодействия пользователей и товаров имеет графовую структуру, а именно, представим в виде двудольного графа, который будем называть {\bf графом взаимодействий пользователей и товаров}, где вершины --- пользователи и товары, а ребра --- взаимодействия: $G = <U \cup I, r>$, для решения задачи рекомендации возможно применение графовых нейронных сетей следующим образом:
\begin{enumerate}
\item Необходимо с помощью графовой нейронной сети для графа взаимодействий пользователей и товаров вычислить векторные представления вершин, соответственно, векторные представления пользователей и товаров: $h_u$ и $h_i$.
\item С помощью скоринговой функции $score$ вычислить приближенные рейтинги пользователя для каждого товара $\hat r_{ui} = score(h_v, h_i)$.
\item в качестве рекомендации пользователю выбирается товар, для которого приближенный рейтинг пользователя максимальный $i_{rec} = \arg \max_i \hat r_{ui}$
\end{enumerate}

Таким образом, вычисленные с помощью графовых нейронных сетей на первом шаге, векторные представления пользователей, благодаря парадигме обмена сообщений, лежащей в основе GNN, будут содержать информацию как о товарах, с которыми провзаимодействовал данный пользователь, так и о других пользователях, которые также провзаимодействовали с данными товарами. То же и для товаров, их векторные представления будут содержать информацию как о пользователях, которые провзаимодействовали с этим товаром, так и о других товарах, с которыми данные пользователи также провзаимодейcтвовали.

Соответственно, {\it основное преимущество} решений задачи рекомендации, основанных на графовых нейронных сетях, является применение одновременно обоих подходов, контентного и коллаборативной фильтрации, благодаря лежащей в основе графовых нейронных сетей парадигме обмена сообщений.

{\it Важной особенностью} графа взаимодействий пользователей и товаров является зависимость его структуры от времени. Между пользователями и товарами возникают новые взаимодействия, количество пользователей и товарой может расти и убывать, что в структуре графа выражается в виде добавления/удаления ребер и вершин. Исходя из этого, для достижения выского качества решения задачи рекомендаций необходимо не только извлекать информацию из графовой стркутуры, но и учитывать её динамику.

\section{Обучение представлений статических графов}
В случае графов, структура которых статична, для вычисления векторных представлений вершин используют статичные графовые нейронные сети. В их основе лежит описанная в предыдущей секции парадигма обмена сообщений, а различия, в основном, заключены в используемых функциях сообщений, агрегации и обновления. Рассмотрим статические графовые нейронные сети, используемые в данной работе.\\

Graph Convolutional Network. Для аггрегации информации от соседей вершины и итеративного обновления векторных представлений использует спектральное разложение Лапласиана графа:
$$m_{uv} = d_{vv}^{-\frac12}a_{uv}d_{uu}^{-\frac{1}{2}} h_u^l$$
$$h_v^{l+1} = \sigma\left(W^l \sum_{u \in N(v)}m_{uv}\right)$$ 
GraphSAGE.
Graph Attention Netowrk.

\section{Обучение представлений динамических графов}
Динамический граф --- граф, структура которого изменяется во времени: $G = <V(t), E(t)>,\: t \in \mathcal{T}$.
Существует два основных способа представления динамических графов:
Дискретное представление динамического графа --- представление динамического графа в виде последовательности статичных графов(снэпшотов), каждый из которых является зафиксированным в определенный момент времени динамический граф.
Графовые нейронные сети для динамических графов являются обобщением статических, используя в основе похожие принципы, допольнительно учитывая временное измерение.
В том случае, когда структура графа, то есть количество 

В случае, когда структура графа может изменяться во времени изспользуют два основных представления
непрерывный и дискретный графы
в дискретном случае основным является фреймворк гцрн
в непрерывном тгн

\section{Обучение с подкреплением}
тбд


\chapter{Графовые модели для решения задачи рекомендаций онлайн}
в этой главе хз просто какой-то шлак

\section{Постановка задачи рекомендаций онлайн}

ставим задачу

\section{Graph Convolutional Q-Network}

GCQN

\section{Предлагаемая модель}

TGQN


\chapter{Вычислительный эксперимент}

\section{Среда и процедура}

asdfafa sdfasdf

\section{Бейзлайн-модели}

asdfafa sdfasdf

\section{Результаты и анализ}

asdfafa sdfasdf


\chapter{Заключение}

Здесь идет текст. Вот так выглядит ссылка на библиографию \cite{langmuir26}. Аналогично добавляются еще главы, внутри них можно объявлять секции с помощью \verb|\section|.


\backmatter

%\printbib
% Следующие строки необходимо раскомментировать, а предыдущую закомментировать, если используется inline-библиография.
\begin{thebibliography}{99}
    \bibitem{langmuir26}
        H. Mott-Smith, I. Langmuir. ``The theory of collectors in gaseous discharges''. \emph{Phys. Rev.} \textbf{28} (1926)
\end{thebibliography}

\chapter{Благодарности}

Благодарности идут тут.

\end{document}